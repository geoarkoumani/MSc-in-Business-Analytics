{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eb71ef",
   "metadata": {},
   "source": [
    "# Machine Learning and Content Analytics – Mini Project\n",
    "\n",
    "# Offensive language and hate speech detection \n",
    "---\n",
    "> Students: `Arkoumani Georgia - p2822104` `Poulou Myrto - p2822129` `Koutsodimitropoulou Anastasia - p2822119` `Zaragka Eftychia - p2822112` <br />\n",
    "> Professor: Haris Papageorgiou (xaris@ilsp.gr) <br />\n",
    "> Assistant responsible for this assignment: George Perakis (gperakis@aueb.gr) <br />\n",
    "> Department of Management Science and Technology <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> Date: 28/08/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c23b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99b8a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yes sort remind eld lady play movie titanic te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lady buy gun learn use effectively kill mother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>amazing dad not forget girl crushs girl mom as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>delon love turkey brave turk indian muslim sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>here thing person earth decide not matter feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381257</th>\n",
       "      <td>1</td>\n",
       "      <td>know woman single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381258</th>\n",
       "      <td>1</td>\n",
       "      <td>woman want mother say want patriarchal society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381259</th>\n",
       "      <td>1</td>\n",
       "      <td>woman submissive man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381260</th>\n",
       "      <td>1</td>\n",
       "      <td>woman essentially childlike unable understand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381261</th>\n",
       "      <td>1</td>\n",
       "      <td>woman allow vote maledominate country place de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1381262 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                         lemmatized\n",
       "0               0  yes sort remind eld lady play movie titanic te...\n",
       "1               0  lady buy gun learn use effectively kill mother...\n",
       "2               0  amazing dad not forget girl crushs girl mom as...\n",
       "3               0  delon love turkey brave turk indian muslim sha...\n",
       "4               0  here thing person earth decide not matter feel...\n",
       "...           ...                                                ...\n",
       "1381257         1                                  know woman single\n",
       "1381258         1     woman want mother say want patriarchal society\n",
       "1381259         1                               woman submissive man\n",
       "1381260         1  woman essentially childlike unable understand ...\n",
       "1381261         1  woman allow vote maledominate country place de...\n",
       "\n",
       "[1381262 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile('more_cleaned_df.zip') \n",
    "df = pd.read_csv('more_cleaned_df.csv')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb30ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Extra shuffle (can be skipped because it is performed in StratifiedKFold)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a265d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial DataFrame is separated into two sub-DataFrames. One containing all positive records and one containing\n",
    "# all negative records\n",
    "df_positive = df[df['category']==1]\n",
    "df_negative = df[df['category']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7248bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chunk size of each DataFrame is initialized. If chunk size exceeds the available positive records\n",
    "# system retrieves as many positive records as can be found.\n",
    "data_length = 100000\n",
    "\n",
    "chunk_size = int(data_length / 2)\n",
    "\n",
    "df_positive_no = chunk_size if len(df_positive) > chunk_size else len(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a1d8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here both sub-DataFrames repeat the process of shuffling.\n",
    "df_negative = shuffle(df_negative)\n",
    "df_negative = df_negative[:chunk_size]\n",
    "\n",
    "df_positive = shuffle(df_positive)\n",
    "df_positive = df_positive[:df_positive_no] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e949dea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>farleftist dickbag like jon stewart comedian f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hoe house tony spot mf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>prefer jameis winston speak tv damn coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch smell like fart holdin th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>horse shit not vandalize page idiot not vandal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>get rid land line month miss get call day tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>not aca add customer national insurance compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>news globe will not report british parliament ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>not agree mean prejudice agree mean open minde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>eastern cape elective conference run main even...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "0             1  farleftist dickbag like jon stewart comedian f...\n",
       "1             1                             hoe house tony spot mf\n",
       "2             1           prefer jameis winston speak tv damn coon\n",
       "3             1              bitch smell like fart holdin th grade\n",
       "4             1  horse shit not vandalize page idiot not vandal...\n",
       "...         ...                                                ...\n",
       "99995         0  get rid land line month miss get call day tele...\n",
       "99996         0  not aca add customer national insurance compan...\n",
       "99997         0  news globe will not report british parliament ...\n",
       "99998         0  not agree mean prejudice agree mean open minde...\n",
       "99999         0  eastern cape elective conference run main even...\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_positive, df_negative]\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0915e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>0</td>\n",
       "      <td>question obama inform august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>0</td>\n",
       "      <td>old remember large panic teach school ozone la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>0</td>\n",
       "      <td>try tell people not judgment good luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>0</td>\n",
       "      <td>welfare bum wait pay cheque not respond hard w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>0</td>\n",
       "      <td>sadly probably right thing africa go bad gay p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>get rid land line month miss get call day tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>not aca add customer national insurance compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>news globe will not report british parliament ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>not agree mean prejudice agree mean open minde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>eastern cape elective conference run main even...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "50000         0                       question obama inform august\n",
       "50001         0  old remember large panic teach school ozone la...\n",
       "50002         0             try tell people not judgment good luck\n",
       "50003         0  welfare bum wait pay cheque not respond hard w...\n",
       "50004         0  sadly probably right thing africa go bad gay p...\n",
       "...         ...                                                ...\n",
       "99995         0  get rid land line month miss get call day tele...\n",
       "99996         0  not aca add customer national insurance compan...\n",
       "99997         0  news globe will not report british parliament ...\n",
       "99998         0  not agree mean prejudice agree mean open minde...\n",
       "99999         0  eastern cape elective conference run main even...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84c977ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>farleftist dickbag like jon stewart comedian f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hoe house tony spot mf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>prefer jameis winston speak tv damn coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch smell like fart holdin th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>horse shit not vandalize page idiot not vandal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>screw want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>sucka hoesucka hoe succsess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch suck ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>hear cunt smell like alley crab factory talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>link appropriate stay advertise arbitration mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "0             1  farleftist dickbag like jon stewart comedian f...\n",
       "1             1                             hoe house tony spot mf\n",
       "2             1           prefer jameis winston speak tv damn coon\n",
       "3             1              bitch smell like fart holdin th grade\n",
       "4             1  horse shit not vandalize page idiot not vandal...\n",
       "...         ...                                                ...\n",
       "49995         1                                         screw want\n",
       "49996         1                        sucka hoesucka hoe succsess\n",
       "49997         1                                    bitch suck ball\n",
       "49998         1       hear cunt smell like alley crab factory talk\n",
       "49999         1  link appropriate stay advertise arbitration mo...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af439c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df[df['category']==1]\n",
    "df_negative = df[df['category']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ad1ae84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c47fa46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0b70710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df[df['category']==1]\n",
    "df_negative = df[df['category']==0]\n",
    "\n",
    "# It is calculated the number of positive records to be created through augmentation process.\n",
    "aug_sentences_to_build_no = len(df_negative) - len(df_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24056ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No need for data augmentation (oversampling). Downsampling to [Class 1] is applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Augmentation Process\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# If there is no record to get created a Exception is raised in order to stop the execution.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# If there are records to be created system proceeds to their creation.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aug_sentences_to_build_no \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo need for data augmentation (oversampling). Downsampling to [Class 1] is applied.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maug_sentences_to_build_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records of [Class 1] are going to be created.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: No need for data augmentation (oversampling). Downsampling to [Class 1] is applied."
     ]
    }
   ],
   "source": [
    "# Augmentation Process\n",
    "# If there is no record to get created a Exception is raised in order to stop the execution.\n",
    "# If there are records to be created system proceeds to their creation.\n",
    "if aug_sentences_to_build_no <= 0:\n",
    "    raise Exception('No need for data augmentation (oversampling). Downsampling to [Class 1] is applied.')\n",
    "else:\n",
    "    print(f'{aug_sentences_to_build_no} records of [Class 1] are going to be created.')\n",
    "    import nlpaug.augmenter.word as naw\n",
    "\n",
    "# SMOTE might lose some of the contextual meanings, which is possibly important for BERT and less so for other simpler models.\n",
    "# Another way of doing class balancing is increasing the number of samples by random word dropout, or synonym replacement. \n",
    "# nlpaug or textaugment python packages are ideal for such a work. In this case scenario sysnonym replacement is applied using\n",
    "# nlpaug python package.\n",
    "aug = naw.SynonymAug(aug_src='wordnet', lang='eng')\n",
    "\n",
    "dict_positive_build = []\n",
    "\n",
    "for _ in range(0, aug_sentences_to_build_no):\n",
    "    df_positive_random_row = df_positive.sample(n=1)\n",
    "    dict_positive_build.append({'category': 1, 'lemmatized': aug.augment(df_positive_random_row.iloc[0]['lemmatized'])[0]})\n",
    "    \n",
    "df_produced = pd.DataFrame(dict_positive_build)\n",
    "\n",
    "frames = [df_positive, df_produced]\n",
    "\n",
    "df_positive_new = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "frames = [df_positive_new, df_negative]\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a2af833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>farleftist dickbag like jon stewart comedian f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hoe house tony spot mf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>prefer jameis winston speak tv damn coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch smell like fart holdin th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>horse shit not vandalize page idiot not vandal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>get rid land line month miss get call day tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>not aca add customer national insurance compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>news globe will not report british parliament ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>not agree mean prejudice agree mean open minde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>eastern cape elective conference run main even...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "0             1  farleftist dickbag like jon stewart comedian f...\n",
       "1             1                             hoe house tony spot mf\n",
       "2             1           prefer jameis winston speak tv damn coon\n",
       "3             1              bitch smell like fart holdin th grade\n",
       "4             1  horse shit not vandalize page idiot not vandal...\n",
       "...         ...                                                ...\n",
       "99995         0  get rid land line month miss get call day tele...\n",
       "99996         0  not aca add customer national insurance compan...\n",
       "99997         0  news globe will not report british parliament ...\n",
       "99998         0  not agree mean prejudice agree mean open minde...\n",
       "99999         0  eastern cape elective conference run main even...\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90542fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>farleftist dickbag like jon stewart comedian f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hoe house tony spot mf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>prefer jameis winston speak tv damn coon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch smell like fart holdin th grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>horse shit not vandalize page idiot not vandal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>screw want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>sucka hoesucka hoe succsess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch suck ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>hear cunt smell like alley crab factory talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>link appropriate stay advertise arbitration mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "0             1  farleftist dickbag like jon stewart comedian f...\n",
       "1             1                             hoe house tony spot mf\n",
       "2             1           prefer jameis winston speak tv damn coon\n",
       "3             1              bitch smell like fart holdin th grade\n",
       "4             1  horse shit not vandalize page idiot not vandal...\n",
       "...         ...                                                ...\n",
       "49995         1                                         screw want\n",
       "49996         1                        sucka hoesucka hoe succsess\n",
       "49997         1                                    bitch suck ball\n",
       "49998         1       hear cunt smell like alley crab factory talk\n",
       "49999         1  link appropriate stay advertise arbitration mo...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5590dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>0</td>\n",
       "      <td>question obama inform august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>0</td>\n",
       "      <td>old remember large panic teach school ozone la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>0</td>\n",
       "      <td>try tell people not judgment good luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>0</td>\n",
       "      <td>welfare bum wait pay cheque not respond hard w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>0</td>\n",
       "      <td>sadly probably right thing africa go bad gay p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>get rid land line month miss get call day tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>not aca add customer national insurance compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>news globe will not report british parliament ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>not agree mean prejudice agree mean open minde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>eastern cape elective conference run main even...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                         lemmatized\n",
       "50000         0                       question obama inform august\n",
       "50001         0  old remember large panic teach school ozone la...\n",
       "50002         0             try tell people not judgment good luck\n",
       "50003         0  welfare bum wait pay cheque not respond hard w...\n",
       "50004         0  sadly probably right thing africa go bad gay p...\n",
       "...         ...                                                ...\n",
       "99995         0  get rid land line month miss get call day tele...\n",
       "99996         0  not aca add customer national insurance compan...\n",
       "99997         0  news globe will not report british parliament ...\n",
       "99998         0  not agree mean prejudice agree mean open minde...\n",
       "99999         0  eastern cape elective conference run main even...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['category']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48e4ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to traing and test data\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['lemmatized'], df['category'], random_state=42, test_size=0.3)\n",
    "df_train = pd.DataFrame(xtrain)\n",
    "label = preprocessing.LabelEncoder()\n",
    "y = label.fit_transform(ytrain)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# we create a BERT embedding layer by importing the BERT model from hub.KerasLayer\n",
    "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "# bert_en_uncased_L-12_H-768_A-12_4.tar.gz\n",
    "bert_layer = hub.KerasLayer(m_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec6a7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase\n",
    "# and finally we pass our vocab_file and do_lower_case variables to the Tokenizer object.\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddcdb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the text\n",
    "# we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase and \n",
    "# finally we pass our vocab_file and do_lower_case variables to the Tokenizer object.\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=512) -> tuple:\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "\n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "\n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "\n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0eaf30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build The Model\n",
    "\n",
    "# Now we are all set to create our model. To do so, we will create a function named build_model that having tf.keras.models.Model class. \n",
    "# Inside the function we will define our model layers. Our model will consist of three Dense neural network layers and also dropout layer. \n",
    "# We have chosen a learning rate to 2e-5.\n",
    "\n",
    "# RELU function :- With default values, this returns max(x, 0), the element-wise maximum of 0 and the input tensor. \n",
    "# Modifying default parameters allows you to use non-zero thresholds, change the max value of the activation, \n",
    "# and to use a non-zero multiple of the input for values below the threshold.\n",
    "\n",
    "# Softmax function :- Softmax converts a real vector to a vector of categorical probabilities. \n",
    "# The elements of the output vector are in range (0, 1) and sum to 1. Each vector is handled independently. \n",
    "# The axis argument sets which axis of the input the function is applied along. \n",
    "# Softmax is often used as the activation for the last layer of a classification network because \n",
    "# the result could be interpreted as a probability distribution. \n",
    "# The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)).\n",
    "\n",
    "# Binary corssentropy:- Computes the cross-entropy loss between true labels and predicted labels. \n",
    "# We can use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). \n",
    "# For each example, there should be a single floating-point value per prediction.\n",
    "\n",
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "\n",
    "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
    "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
    "    out = tf.keras.layers.Dense(2, activation='softmax')(lay)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb7a7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding max length of documents\n",
    "# len(max(df['lemmatized'].tolist(), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16ff167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_2 (KerasLayer)     [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 768)         0           ['keras_layer_2[0][1]']          \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           49216       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 2)            66          ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,603\n",
      "Trainable params: 109,533,602\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Finding max length of documents\n",
    "# Here we check only the first 128 characters of each text, and also we set train-test input and train labels\n",
    "max_len = 128\n",
    "train_input = bert_encode(xtrain, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(xtest, tokenizer, max_len=max_len)\n",
    "train_labels = y\n",
    "\n",
    "labels = label.classes_\n",
    "labels\n",
    "\n",
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef35532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.8843 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.90850, saving model to model.h5\n",
      "1750/1750 [==============================] - 19777s 11s/step - loss: 0.2711 - accuracy: 0.8843 - val_loss: 0.2095 - val_accuracy: 0.9085\n",
      "Epoch 2/2\n",
      "1750/1750 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9231 \n",
      "Epoch 2: val_accuracy improved from 0.90850 to 0.91629, saving model to model.h5\n",
      "1750/1750 [==============================] - 19288s 11s/step - loss: 0.1835 - accuracy: 0.9231 - val_loss: 0.2066 - val_accuracy: 0.9163\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "train_sh = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=2,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "270b513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 378). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Faey\\Desktop\\FINAL NOTEBOOKS\\bert_finalized_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Faey\\Desktop\\FINAL NOTEBOOKS\\bert_finalized_model\\assets\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath('')\n",
    "# save the model to disk\n",
    "filename = os.path.join(path, 'bert_finalized_model')\n",
    "\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8eab7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model = tf.keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "922ac4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "y_t = label.fit_transform(ytest)\n",
    "y_t = to_categorical(y_t)\n",
    "\n",
    "test_labels = y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f09101a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d174c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(predictions, axis=1)\n",
    "y_test=np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca9ec58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9109666666666667\n",
      "Accuracy Percentage 91.09666666666666 %:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) # Value between 0 and 1\n",
    "\n",
    "print(\"Accuracy Percentage {} %:\".format(100*accuracy_score(y_test, y_pred))) # Value between 0 and 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "188543298b82ebbcb8e70010509407fe8cebdf9623eadef5d2d9137c4c2e7377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
